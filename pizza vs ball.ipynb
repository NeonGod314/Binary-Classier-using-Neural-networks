{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @Shubham Kumar Singh\n",
    "\n",
    "## Digital enterprise, Advisian\n",
    "\n",
    "### Consits 2 models for binary classification b/w class0 and class1\n",
    "#### Model 1: 2 layered\n",
    "#### Model 2: 5 layered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_backbone import *\n",
    "import glob\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# don't touch_ sets parameters for plots_______________________________\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# _____________________________________________________________________\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading my data\n",
    "#train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "# Example of a picture\n",
    "# Explore your dataset \n",
    "#m_train = train_x_orig.shape[0]\n",
    "#num_px = train_x_orig.shape[1]\n",
    "#m_test = test_x_orig.shape[0]\n",
    "\n",
    "#print (\"Number of training examples: \" + str(m_train))\n",
    "#print (\"Number of testing examples: \" + str(m_test))\n",
    "#print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "#print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "#print (\"train_y shape: \" + str(train_y.shape))\n",
    "#print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "#print (\"test_y shape: \" + str(test_y.shape))\n",
    "# Reshape the training and test examples \n",
    "#train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "#test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "#train_x = train_x_flatten/255.\n",
    "#test_x = test_x_flatten/255.\n",
    "\n",
    "#print (\"train_x's shape: \" + str(train_x.shape))\n",
    "#print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Shape of Input matrix  : (12288, 82)\n",
      "Training: Shape of Output matrix : (1, 82)\n",
      "Training: Shape of Input matrix  : (12288, 24)\n",
      "Training: Shape of Output matrix : (1, 24)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#loading dataset for TRAINING________________________________________________________\n",
    "\n",
    "file_pizza=glob.glob('class0/*.jpg')\n",
    "file_sunflower=glob.glob('class1/*.jpg')\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "#pizza\n",
    "for file in file_pizza:\n",
    "    img=np.array(mpimg.imread(file))\n",
    "    #print(img.shape)\n",
    "       \n",
    "    img_flatten = img.reshape(12288,1) \n",
    "    #print(img_flatten.shape)\n",
    "    standard_img=img_flatten / 255.\n",
    "    x_train.append(standard_img)\n",
    "    #print(standard_img)\n",
    "    y_train.append(0)\n",
    "\n",
    "    \n",
    "\n",
    "#sunflower\n",
    "for file in file_sunflower:\n",
    "    img=np.array(mpimg.imread(file))\n",
    "    #print(img.shape)\n",
    "       \n",
    "    img_flatten = img.reshape(12288,1) \n",
    "    #print(img_flatten.shape)\n",
    "    standard_img=img_flatten / 255.\n",
    "    x_train.append(standard_img)\n",
    "    #print(standard_img)\n",
    "    y_train.append(1)\n",
    "      \n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "\n",
    "x_train=np.squeeze(x_train)\n",
    "train_x=x_train.T\n",
    "train_y=y_train.reshape(1,82)\n",
    "\n",
    "print(\"Training: Shape of Input matrix  :\",train_x.shape)\n",
    "print(\"Training: Shape of Output matrix :\",train_y.shape)\n",
    "\n",
    "#loading dataset for TEST\n",
    "file_pizza_test=glob.glob('class0_test/*.jpg')\n",
    "file_sunflower_test=glob.glob('class1_test/*.jpg')\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "#pizza\n",
    "for file in file_pizza_test:\n",
    "    img_test=np.array(mpimg.imread(file))\n",
    "    #print(img.shape)\n",
    "       \n",
    "    img_flatten_test = img_test.reshape(12288,1) \n",
    "    #print(img_flatten.shape)\n",
    "    standard_img_test=img_flatten_test / 255.\n",
    "    x_test.append(standard_img_test)\n",
    "    #print(standard_img)\n",
    "    y_test.append(0)\n",
    "    \n",
    "\n",
    "#sunflower\n",
    "for file in file_sunflower_test:\n",
    "    img_test=np.array(mpimg.imread(file))\n",
    "    #print(img.shape)\n",
    "       \n",
    "    img_flatten_test = img_test.reshape(12288,1) \n",
    "    #print(img_flatten.shape)\n",
    "    standard_img_test=img_flatten_test / 255.\n",
    "    x_test.append(standard_img_test)\n",
    "    #print(standard_img)\n",
    "    y_test.append(1)\n",
    "      \n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "x_test=np.squeeze(x_test)\n",
    "test_x=x_test.T\n",
    "test_y=y_test.reshape(1,24)\n",
    "\n",
    "print(\"Training: Shape of Input matrix  :\",test_x.shape)\n",
    "print(\"Training: Shape of Output matrix :\",test_y.shape)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1)\n",
      "[1]\n",
      "Training: Shape of Input matrix  : (12288, 1)\n",
      "Training: Shape of Output matrix : (1, 1)\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "#input single test\n",
    "\n",
    "#loading dataset for TEST\n",
    "single_test=\"image_0001.jpg\"\n",
    "single_x=[]\n",
    "single_y=[]\n",
    "\n",
    "single_img=np.array(mpimg.imread(single_test))\n",
    "       \n",
    "single_img_flatten  = single_img.reshape(12288,1) \n",
    "print(single_img_flatten.shape)\n",
    "single_standard_img = single_img_flatten/ 255.\n",
    "single_x.append(single_standard_img)\n",
    "#print(single_standard_img)\n",
    "single_y.append(1) #input the class mannualy here\n",
    "\n",
    "\n",
    "single_x=np.array(single_x)\n",
    "single_y=np.array(single_y)\n",
    "print(single_y)\n",
    "\n",
    "single_x=np.squeeze(single_x)\n",
    "single_x=(single_x.T).reshape(12288,1)\n",
    "single_y=single_y.reshape(1,1)\n",
    "\n",
    "print(\"Training: Shape of Input matrix  :\",single_x.shape)\n",
    "print(\"Training: Shape of Output matrix :\",single_y.shape)\n",
    "print(single_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS DEFINING THE MODEL ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: two_layer_model\n",
    "\n",
    "\"\"\"\n",
    "    LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X              = input data, of shape (n_x, number of examples)\n",
    "    Y              = true \"label\" vector (containing 0 if class0, 1 if class1),[1, number of examples]\n",
    "    layers_dims    = dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations = number of iterations of the optimization loop\n",
    "    learning_rate  = learning rate of the gradient descent update rule\n",
    "    print_cost     = If set to True, this will print the cost every 100 iterations \n",
    "    Returns        = parameters :a dictionary containing W1, W2, b1, and b2\n",
    "\"\"\"\n",
    "\n",
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop for gradient descent\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1\". Output: \"A1, cache1, A2, cache2\".\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, activation='relu')\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, activation='sigmoid')\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation.Inputs=\"dA2, cache2, cache1\".Outputs:\"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation='sigmoid')\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation='relu')\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print cost every 100 iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6933180224300244\n",
      "Cost after iteration 100: 0.49585826626736157\n",
      "Cost after iteration 200: 0.08355143894106362\n",
      "Cost after iteration 300: 0.03381357521676777\n",
      "Cost after iteration 400: 0.01940931247961935\n",
      "Cost after iteration 500: 0.013100538928063196\n",
      "Cost after iteration 600: 0.009682764530078469\n",
      "Cost after iteration 700: 0.007579503510803244\n",
      "Cost after iteration 800: 0.006171195024260272\n",
      "Cost after iteration 900: 0.005170535499654639\n",
      "Cost after iteration 1000: 0.004427400497740569\n",
      "Cost after iteration 1100: 0.0038562901522231105\n",
      "Cost after iteration 1200: 0.003405221719629366\n",
      "Cost after iteration 1300: 0.0030410082782722143\n",
      "Cost after iteration 1400: 0.0027415015428399175\n",
      "Cost after iteration 1500: 0.0024913559714152063\n",
      "Cost after iteration 1600: 0.0022796562310664374\n",
      "Cost after iteration 1700: 0.002098436839697107\n",
      "Cost after iteration 1800: 0.0019417538551525703\n",
      "Cost after iteration 1900: 0.0018050903168948043\n",
      "Cost after iteration 2000: 0.0016849548981037537\n",
      "Cost after iteration 2100: 0.0015786318050985703\n",
      "Cost after iteration 2200: 0.0014839297630393374\n",
      "Cost after iteration 2300: 0.001399094893169452\n",
      "Cost after iteration 2400: 0.0013227196405433087\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS: dimensios of the layer________________\n",
    "\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  5-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L_layer_model\n",
    "\n",
    "    #[LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X = data, numpy array of shape [number of examples, num_px * num_px * 3]\n",
    "    Y = true \"label\" vector (containing 0 if class0, 1 if class1), [1, number of examples]\n",
    "    layers_dims    = list containing the input size and each layer size, of length number of layers + 1\n",
    "    learning_rate  = learning rate of the gradient descent update rule\n",
    "    num_iterations = number of iterations of the optimization loop\n",
    "    print_cost     = if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters     = parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         \n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pred_test = predict(single_x, single_y, parameters)\n",
    "\n",
    "plt.imshow(np.array(ndimage.imread(single_test, flatten=False)))"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "TSPse",
   "launcher_item_id": "24mxX"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
